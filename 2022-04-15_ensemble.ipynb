{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[previous file - EDA](2022-03-31_train-test_EDA.ipynb)\n",
    "\n",
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost lightgbm xgboost optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\polyape1\\Desktop\\sf_project_6\\venv\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from warnings import filterwarnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, StackingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "sns.set()\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115367, 30), (34686, 28))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.read_parquet(\"https://github.com/XelorR/sf_project_6/raw/master/data/2022-04-08_train_pre-model.parquet\")\n",
    "test_raw = pd.read_parquet(\"https://github.com/XelorR/sf_project_6/raw/master/data/2022-04-08_test_pre-model.parquet\")\n",
    "\n",
    "train_raw.shape, test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_or_load(clf, X, y, filepath: str, complevel=9):\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            clf = joblib.load(f)\n",
    "    else:\n",
    "        clf.fit(X, y)\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            joblib.dump(clf, f, compress=complevel)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def submit(hold_out: pd.DataFrame, model, name=\"submission\"):\n",
    "    preds = model.predict(hold_out)\n",
    "    submission = pd.read_csv(\"https://github.com/XelorR/sf_project_6/raw/master/data/sample_submission.csv\")\n",
    "    submission[\"price\"] = preds\n",
    "    submission.to_csv(f\"{name}.csv\", index=False)\n",
    "    \n",
    "\n",
    "def submit_log(hold_out: pd.DataFrame, model, name=\"submission\"):\n",
    "    preds = model.predict(hold_out)\n",
    "    submission = pd.read_csv(\"https://github.com/XelorR/sf_project_6/raw/master/data/sample_submission.csv\")\n",
    "    submission[\"price\"] = np.exp(preds)\n",
    "    submission.to_csv(f\"{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw[\"train/test\"] = \"train\"\n",
    "test_raw[\"train/test\"] = \"test\"\n",
    "\n",
    "data = train_raw.append(test_raw)\n",
    "data[\"ptc\"].fillna(\"Оригинал\", inplace=True)\n",
    "\n",
    "data[data.select_dtypes(\"object\").columns.tolist()] = data[\n",
    "    data.select_dtypes(\"object\").columns.tolist()\n",
    "].astype(str)\n",
    "\n",
    "for col in set(data.select_dtypes(exclude=(\"object\")).columns) - {\"price\"}:\n",
    "    data[col] = (\n",
    "        RobustScaler().fit_transform(data[col].values.reshape(-1, 1)).reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "for col in [\"model_name\"]:\n",
    "    data[col] = LabelEncoder().fit_transform(data[col].astype(\"str\"))\n",
    "\n",
    "data = pd.get_dummies(\n",
    "    data,\n",
    "    columns=[\n",
    "        \"vehicle_transmission\",\n",
    "        \"vendor\",\n",
    "        \"brand\",\n",
    "        \"fuel_type\",\n",
    "        \"body_type\",\n",
    "        \"color\",\n",
    "        \"ptc\",\n",
    "        \"drive\",\n",
    "        \"wheel\",\n",
    "        \"age_cat\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "train = data.loc[data[\"train/test\"] == \"train\"]\n",
    "\n",
    "train_jane = train.loc[train[\"sample\"] == \"jane\"]\n",
    "train_sokolov = train.loc[train[\"sample\"] == \"sokolov\"]\n",
    "train_jane[\"price\"] = train_jane[\"price\"] * 0.86\n",
    "train = train_jane.append(train_sokolov)\n",
    "\n",
    "train.drop(columns=[\"sample\", \"description\", \"train/test\"], inplace=True)\n",
    "test = data.loc[data[\"train/test\"] == \"test\"].drop(\n",
    "    columns=[\"sample\", \"description\", \"train/test\", \"price\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86525, 112), (86525,), (28842, 112), (28842,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop(columns=\"price\"), train[\"price\"], random_state = 42, shuffle=True)\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "lightgbm_optuned 0.1562352982059385\n"
     ]
    }
   ],
   "source": [
    "lightgbm_optuned = LGBMRegressor(\n",
    "    **{\n",
    "        \"bagging_fraction\": 0.9079273070338828,\n",
    "        \"bagging_freq\": 4,\n",
    "        \"feature_fraction\": 0.716472706585253,\n",
    "        \"lambda_l1\": 0.0007127314011370048,\n",
    "        \"lambda_l2\": 1.4991431139899208e-08,\n",
    "        \"learning_rate\": 0.24273738931459424,\n",
    "        \"min_child_samples\": 27,\n",
    "        \"num_leaves\": 129,\n",
    "        \"random_state\": 42,\n",
    "        \"silent\": True,\n",
    "    }\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm_optuned 0.1562352982059385\n"
     ]
    }
   ],
   "source": [
    "print(\"lightgbm_optuned\", mean_absolute_percentage_error(y_valid, lightgbm_optuned.predict(X_valid)))\n",
    "submit(test, lightgbm_optuned, \"lightgbm_optuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7849386830734889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7849386830734889\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6405456215002115e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6405456215002115e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.999471799816821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.999471799816821\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9256724979441087, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9256724979441087\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "lightgbm_optuned_1899_log 0.1266083430966481\n"
     ]
    }
   ],
   "source": [
    "lightgbm_optuned_1899 = LGBMRegressor(\n",
    "    **{\n",
    "        'learning_rate': 0.2200394016092361, \n",
    "        'lambda_l1': 3.6405456215002115e-08, \n",
    "        'lambda_l2': 3.9256724979441087, \n",
    "        'num_leaves': 251, \n",
    "        'feature_fraction': 0.7849386830734889, \n",
    "        'bagging_fraction': 0.999471799816821, \n",
    "        'bagging_freq': 7, \n",
    "        'min_child_samples': 5, \n",
    "        \"random_state\": 42,\n",
    "        \"silent\": True\n",
    "    }\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm_optuned_1899_log 0.1266083430966481\n"
     ]
    }
   ],
   "source": [
    "print(\"lightgbm_optuned_1899_log\", mean_absolute_percentage_error(y_valid, np.exp(lightgbm_optuned_1899.predict(X_valid))))\n",
    "submit_log(test, lightgbm_optuned_1899, \"lightgbm_optuned_log_1899\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8139002011435048, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8139002011435048\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.6905457446408715e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6905457446408715e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9996914517711281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9996914517711281\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.410817513919556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.410817513919556\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "lightgbm_optuned_1258_log 0.12681490786747857\n"
     ]
    }
   ],
   "source": [
    "lightgbm_optuned_1258 = LGBMRegressor(\n",
    "    **{\n",
    "        'learning_rate': 0.2034225924278744, \n",
    "        'lambda_l1': 1.6905457446408715e-07, \n",
    "        'lambda_l2': 3.410817513919556, \n",
    "        'num_leaves': 237, \n",
    "        'feature_fraction': 0.8139002011435048, \n",
    "        'bagging_fraction': 0.9996914517711281, \n",
    "        'bagging_freq': 2, \n",
    "        'min_child_samples': 5\n",
    "    }\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm_optuned_1258_log 0.12681490786747857\n"
     ]
    }
   ],
   "source": [
    "print(\"lightgbm_optuned_1258_log\", mean_absolute_percentage_error(y_valid, np.exp(lightgbm_optuned_1258.predict(X_valid))))\n",
    "submit_log(test, lightgbm_optuned_1258, \"lightgbm_optuned_log_1258\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1 (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbgr_custom = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.5,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=12,\n",
    "    alpha=1,\n",
    "    n_estimators=1000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbgr_custom_log 0.1196754335163977\n"
     ]
    }
   ],
   "source": [
    "print(\"xbgr_custom_log\", mean_absolute_percentage_error(y_valid, np.exp(xbgr_custom.predict(X_valid))))\n",
    "submit_log(test, lightgbm_optuned_1258, \"xbgr_custom_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extra trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1 (tuned by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr_cust = ExtraTreesRegressor(\n",
    "    n_estimators=800,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='auto',\n",
    "    max_depth=15,\n",
    "    bootstrap=True,\n",
    "    random_state=42, \n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etr_cust_log 0.13762780765198146\n"
     ]
    }
   ],
   "source": [
    "print(\"etr_cust_log\", mean_absolute_percentage_error(y_valid, np.exp(etr_cust.predict(X_valid))))\n",
    "submit_log(test, etr_cust, \"etr_cust_log\")\n",
    "# etr_cust_log 0.1376278076519815"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2 (optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr_tuned_78 = ExtraTreesRegressor(\n",
    "    **{\n",
    "        'n_estimators': 936, \n",
    "        'min_samples_split': 3, \n",
    "        'min_samples_leaf': 1, \n",
    "        'max_samples': 0.9894458395539251, \n",
    "        'max_features': 'auto',\n",
    "        'max_depth': None,\n",
    "        'bootstrap': True,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': 0\n",
    "    }\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etr_tuned_78_log 0.1243004166689037\n"
     ]
    }
   ],
   "source": [
    "print(\"etr_tuned_78_log\", mean_absolute_percentage_error(y_valid, np.exp(etr_tuned_78.predict(X_valid))))\n",
    "submit_log(test, etr_tuned_78, \"etr_tuned_78_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 3 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr_default = ExtraTreesRegressor().fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etr_default_log 0.12949125299183772\n"
     ]
    }
   ],
   "source": [
    "print(\"etr_default_log\", mean_absolute_percentage_error(y_valid, np.exp(etr_default.predict(X_valid))))\n",
    "submit_log(test, etr_default, \"etr_default_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1 (tuned by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuned = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=800,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='log2',\n",
    "    max_depth=None,\n",
    "    bootstrap=True\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_tuned_log 0.1315218319297354\n"
     ]
    }
   ],
   "source": [
    "print(\"rf_tuned_log\", mean_absolute_percentage_error(y_valid, np.exp(rf_tuned.predict(X_valid))))\n",
    "submit_log(test, rf_tuned, \"rf_tuned_log\")\n",
    "# rf_tuned_log 0.1315354887566232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optuned_174 = RandomForestRegressor(\n",
    "    **{\n",
    "        'n_estimators': 450, \n",
    "        'min_samples_split': 4, \n",
    "        'min_samples_leaf': 2, \n",
    "        'max_samples': 0.9899165552020569, \n",
    "        'max_features': 'auto',\n",
    "        'random_state': 42,\n",
    "        'max_depth': None,\n",
    "        'bootstrap': True\n",
    "    }\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_optuned_174_log 0.12683767196612786\n"
     ]
    }
   ],
   "source": [
    "print(\"rf_optuned_174_log\", mean_absolute_percentage_error(y_valid, np.exp(rf_optuned_174.predict(X_valid))))\n",
    "submit_log(test, rf_optuned_174, \"rf_optuned_log_174\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 3 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_default = RandomForestRegressor().fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_default_log 0.1273281116849625\n"
     ]
    }
   ],
   "source": [
    "print(\"rf_default_log\", mean_absolute_percentage_error(y_valid, np.exp(rf_default.predict(X_valid))))\n",
    "submit_log(test, rf_default, \"rf_default_log\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc97230471a50d03a39de2ef2db4cb6697cabc3209032c45f8c922658807cbc7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
